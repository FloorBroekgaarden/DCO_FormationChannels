{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0b9255c",
   "metadata": {},
   "source": [
    "##### Note \n",
    "Note that there is a python version that creates the csv files of this document, to save time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef902044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------\n",
      "at  BBH\n",
      "at BPS model  K\n",
      "running xparam  t_delay\n",
      "at Channel:  classic\n",
      "adding case A MT systems (channel 5)\n",
      "at Channel:  stable B no CEE\n",
      "adding case A MT systems (channel 6)\n",
      "at Channel:  other\n",
      "at Channel:  immediate CE\n",
      "at Channel:  double-core CE\n",
      "saved data,  BBH t_delay\n",
      "at BPS model  L\n",
      "running xparam  t_delay\n",
      "at Channel:  classic\n",
      "adding case A MT systems (channel 5)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 6] Can't read data (file read failed: time = Fri Feb 23 13:34:59 2024\n, filename = '/Volumes/SimonsFoundation/DataDCO/rapid/COMPASCompactOutput_BBH_L.h5', file descriptor = 73, errno = 6, error message = 'Device not configured', buf = 0x168000000, total read size = 59643064, bytes this sub-read = 59643064, bytes actually read = 18446744073709551615, offset = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 319\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDONE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# run create pandas efficiently \u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m \u001b[43mrun_create_median\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunCreatePDfilesQuantilesDCO_form_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 295\u001b[0m, in \u001b[0;36mrun_create_median\u001b[0;34m(RunCreatePDfilesQuantilesDCO_form_channels, RunCreatePDfilesQuantilesDCO_totals)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m ind_bps, BPSmodelName \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(BPSnameslist[\u001b[38;5;241m10\u001b[39m:]):\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m#             for ind_bps, BPSmodelName in enumerate([BPSnameslist[0]]):\u001b[39;00m\n\u001b[1;32m    293\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat BPS model \u001b[39m\u001b[38;5;124m'\u001b[39m, BPSmodelName)\n\u001b[0;32m--> 295\u001b[0m                 df \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_pd_redshift_from_xparam_for_fc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantile_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantile_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBPSmodelName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBPSmodelName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDCOtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDCOtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_type\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#, pd_file_path=pd_file_path)\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m RunCreatePDfilesQuantilesDCO_totals\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m DCOtype \u001b[38;5;129;01min\u001b[39;00m DCOTypeList:\n",
      "Cell \u001b[0;32mIn[1], line 139\u001b[0m, in \u001b[0;36mcreate_pd_redshift_from_xparam_for_fc\u001b[0;34m(DCOtype, BPSmodelName, pathData, quantile_values, weights_type)\u001b[0m\n\u001b[1;32m    137\u001b[0m     fparam_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_intrinsicFormationPerRedshift\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m     weightheader \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwform_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m mssfr \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_z_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m  \u001b[38;5;28mstr\u001b[39m(redshift)\n\u001b[0;32m--> 139\u001b[0m weights_ \u001b[38;5;241m=\u001b[39m \u001b[43mfdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfparam_key\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mweightheader\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()    \n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# we do not care about the very small rates, so do not report medians for formation channels at redshifts that dont pass the minimum channel contribution\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(weights_)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1E-4\u001b[39m:  \u001b[38;5;66;03m# and we dont want to calculate medians when the total rate is just super low \u001b[39;00m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/ipykernel_py39/lib/python3.9/site-packages/h5py/_hl/dataset.py:768\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "File \u001b[0;32mh5py/_selector.pyx:376\u001b[0m, in \u001b[0;36mh5py._selector.Reader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 6] Can't read data (file read failed: time = Fri Feb 23 13:34:59 2024\n, filename = '/Volumes/SimonsFoundation/DataDCO/rapid/COMPASCompactOutput_BBH_L.h5', file descriptor = 73, errno = 6, error message = 'Device not configured', buf = 0x168000000, total read size = 59643064, bytes this sub-read = 59643064, bytes actually read = 18446744073709551615, offset = 0)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../../common_code')\n",
    "from PostProcessingScripts import * \n",
    "from formation_channels import * \n",
    "import astropy.stats\n",
    "\n",
    "##########\n",
    "# define colors for formation channels \n",
    "# channelColorDict = {'classic':'#118AB2', 'stable B no CEE':'orange',  'immediate CE': '#EF476F'  , r'double-core CE':'#073B4C', 'other':'gray', 'vi':'cyan', 'vii':'#FFD166'}\n",
    "List_formationchannelOptions = ['All',  'classic',  'stable B no CEE',  'immediate CE',  r'double-core CE', 'vi', 'vii', 'other']\n",
    "ind_formationchannelOptions = [7,  1, 2, 3, 4, 5, 6, 0]\n",
    "dictFormationChannelIndex =  {List_formationchannelOptions[i]: ind_formationchannelOptions[i] for i in range(len(List_formationchannelOptions))}\n",
    "\n",
    "# channelColorDict_lighter = {'classic':adjust_lightness(color='#118AB2', amount=1.6),'stable B no CEE':adjust_lightness(color='orange', amount=1.4), 'immediate CE':adjust_lightness(color='#EF476F', amount=1.2),\\\n",
    "                            # r'double-core CE':adjust_lightness(color='#073B4C', amount=1.8), 'other':adjust_lightness(color='gray', amount=1.5),  'vi':adjust_lightness(color='cyan', amount=1.5), 'vii':adjust_lightness(color='#FFD166', amount=1.2)}\n",
    "# channelList = ['classic', 'stable B no CEE', 'vii',  'immediate CE',  r'double-core CE', 'other'] #, 'vi']\n",
    "#######\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def obtain_redshiftsruns(pathData = '/Volumes/SimonsFoundation/DataDCO/'):\n",
    "    BPSmodelName='B'\n",
    "    DCOtype='BNS'\n",
    "    path_ = '/Volumes/SimonsFoundation/DataDCO/' + alphabetDirDict[BPSmodelName] +'/'\n",
    "    path  = path_ + 'COMPASCompactOutput_'+ DCOtype +'_' + BPSmodelName + '.h5'\n",
    "    fdata = h5.File(path, 'r')\n",
    "    redshifts = fdata['redshifts']['redshift'][...].squeeze()\n",
    "    fdata.close()\n",
    "    return redshifts \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# adjustedChannelList = ['classic', 'stable B no CEE',  'immediate CE',  r'double-core CE', 'other']\n",
    "pathData='/Volumes/SimonsFoundation/DataDCO/' # path to datafiles \n",
    "redshifts_runs = obtain_redshiftsruns(pathData = pathData) # obtain redshifts that were run \n",
    "# print('available redshifts:', redshifts_runs) \n",
    "# print(MSSFRnameslist)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_pd_redshift_from_xparam_for_fc(DCOtype='BHNS', BPSmodelName='A', pathData='/Volumes/SimonsFoundation/DataDCO/', quantile_values=[0.5, 0.25, 0.75],\\\n",
    "                                               weights_type='merger'):\n",
    "    \"\"\"\n",
    "    whichplot='rate', 'ratio'\n",
    "    \n",
    "    \"\"\"\n",
    "    redshifts_runs = obtain_redshiftsruns(pathData = pathData) # obtain redshifts that were run    \n",
    "    adjustedChannelList, DCOname = dict_channel_list[DCOtype], DCOname_dict[DCOtype]\n",
    "\n",
    "    full_data_path = pathData + alphabetDirDict[BPSmodelName] +'/COMPASCompactOutput_'+ DCOtype +'_' + BPSmodelName + '.h5'     # path for files \n",
    "    fdata = h5.File(full_data_path,'r')     # read in data \n",
    "    \n",
    "    massCO_ZAMSM1 = fdata['doubleCompactObjects']['M1'][...].squeeze()\n",
    "    massCO_ZAMSM2 = fdata['doubleCompactObjects']['M2'][...].squeeze()\n",
    "    # M1 will be the most massive, M2 the least massive compact object. \n",
    "    massCO_LVKM1, massCO_LVKM2 = obtainM1BHandM2BHassymetric(m1=fdata['doubleCompactObjects']['M1'][...].squeeze(), m2=fdata['doubleCompactObjects']['M2'][...].squeeze()) \n",
    "    MassRatioCO_LVK = massCO_LVKM2/massCO_LVKM1\n",
    "    \n",
    "    channels = fdata['doubleCompactObjects']['formaton channel'][...].squeeze()\n",
    "    \n",
    "    xparams_to_run = ['t_delay']#['mass_1_LVK', 'mass_2_LVK',  'mass_tot', 't_delay', 'mass_ratio_LVK', 'qZAMS', 'separationInitial', 'M1ZAMS', 'M2ZAMS']\n",
    "    for xparam in xparams_to_run: \n",
    "        print('running xparam ', xparam)\n",
    "        \n",
    "        pd_file_path = './formation_median/'+ xparam + '_' + DCOtype + '_' + BPSmodelName + '_' + xparam + '_w_' + weights_type + '.csv'\n",
    "\n",
    "        # make this a dictionary instead !!\n",
    "        if xparam=='chirp_mass_LVK':\n",
    "            param_x = chirpmass(massCO_LVKM1, massCO_LVKM2)\n",
    "        elif xparam=='mass_tot':\n",
    "            param_x = massCO_LVKM1 + massCO_LVKM2\n",
    "        elif xparam=='mass_ratio_LVK':\n",
    "            param_x = MassRatioCO_LVK\n",
    "        elif xparam=='mass_1_LVK':\n",
    "            param_x = massCO_LVKM1\n",
    "        elif xparam=='mass_2_LVK':\n",
    "            param_x = massCO_LVKM2\n",
    "        elif xparam=='log10_t_delay':\n",
    "            param_x = (fdata['doubleCompactObjects']['tform'][...].squeeze() +  fdata['doubleCompactObjects']['tc'][...].squeeze() ) / 1000 # divide by 1000 to make it in [Gyr]\n",
    "            param_x = np.log10(param_x)\n",
    "        elif xparam=='t_delay':\n",
    "            param_x = (fdata['doubleCompactObjects']['tform'][...].squeeze() +  fdata['doubleCompactObjects']['tc'][...].squeeze() ) / 1000 # divide by 1000 to make it in [Gyr]\n",
    "        elif xparam=='M1ZAMS':\n",
    "            param_x = fdata['doubleCompactObjects']['M1ZAMS'][...].squeeze()\n",
    "        elif xparam=='M2ZAMS':\n",
    "            param_x = fdata['doubleCompactObjects']['M2ZAMS'][...].squeeze()\n",
    "        elif xparam=='qZAMS':\n",
    "            param_x = fdata['doubleCompactObjects']['M2ZAMS'][...].squeeze() / fdata['doubleCompactObjects']['M1ZAMS'][...].squeeze()\n",
    "        elif xparam=='separationInitial':\n",
    "            param_x = fdata['doubleCompactObjects']['separationInitial'][...].squeeze()\n",
    "        del massCO_ZAMSM1\n",
    "        del massCO_ZAMSM2\n",
    "        del massCO_LVKM2\n",
    "        del massCO_LVKM1\n",
    "        del MassRatioCO_LVK\n",
    "    \n",
    "        nZ = len(redshifts_runs)\n",
    "        fc_data = np.zeros((nZ, 1)) # create empty dataset for redshifts \n",
    "        fc_data[:,0] = np.round(redshifts_runs,4)  # fill with redshift data rounded to 4 digits \n",
    "        df = pd.DataFrame(fc_data, columns=[\"redshift\"])\n",
    "\n",
    "    \n",
    "        for nrC, Channel in enumerate(adjustedChannelList): \n",
    "            # obtain fc_mask for the requested channel name \n",
    "            print('at Channel: ', Channel)\n",
    "            ind_wanted = dictFormationChannelIndex[Channel]\n",
    "            mask_MRR = (channels==ind_wanted)\n",
    "            if Channel=='stable B no CEE': # add subchannel vii (case A MT to this channel)\n",
    "                mask_MRR=  (channels==ind_wanted) | (channels==6)\n",
    "                print('adding case A MT systems (channel 6)')\n",
    "            elif Channel=='classic': # add subchannel vi (case A MT to this channel)\n",
    "                mask_MRR=  (channels==ind_wanted) | (channels==5)\n",
    "                print('adding case A MT systems (channel 5)')\n",
    "            for ind_mssfr, mssfr in enumerate(MSSFRnameslist[1:]):\n",
    "\n",
    "                median_at_redshifts = np.zeros_like(redshifts_runs)\n",
    "\n",
    "                data_to_add = np.zeros((nZ, len(quantile_values)))\n",
    "                data_to_add[:] = np.nan # start with nan values so that we do not plot datapoint if it doesnt exist \n",
    "\n",
    "                column_names = [Channel + 'xyz_' + mssfr+ ' q_' + str(quantile_values[i]) for i in range(len(quantile_values))] # creates array with header names \n",
    "\n",
    "                for z_ind, redshift in enumerate(redshifts_runs[:]):\n",
    "                    redshift = np.round(redshift,4)\n",
    "\n",
    "                    if weights_type=='merger':\n",
    "                        fparam_key = 'weights_intrinsicPerRedshift'\n",
    "                        weightheader = 'w_' + mssfr + '_z_' +  str(redshift)\n",
    "                    elif weights_type=='formation':\n",
    "                        fparam_key = \"weights_intrinsicFormationPerRedshift\"\n",
    "                        weightheader = 'wform_' + mssfr + '_z_' +  str(redshift)\n",
    "                    weights_ = fdata[fparam_key][weightheader][...].squeeze()    \n",
    "                    \n",
    "                    \n",
    "                    # we do not care about the very small rates, so do not report medians for formation channels at redshifts that dont pass the minimum channel contribution\n",
    "                    if np.sum(weights_)>1E-4:  # and we dont want to calculate medians when the total rate is just super low \n",
    "                        fractional_contribution_fc = np.sum(weights_[mask_MRR])/np.sum(weights_) # contribution of the channel at this redshift \n",
    "                        if fractional_contribution_fc>=minimum_fractional_contribution_fc: \n",
    "                            data_to_add[z_ind] = weighted_quantile(values=param_x[mask_MRR], quantiles=quantile_values, sample_weight=weights_[mask_MRR])\n",
    "#                     else:\n",
    "#                         print('skipping channel', Channel, ' because fractional contribution is ', fractional_contribution_fc)\n",
    "\n",
    "                        \n",
    "                df_to_add = pd.DataFrame(data_to_add, columns=column_names)\n",
    "                df = pd.concat([df, df_to_add], axis=1)        \n",
    "        \n",
    "\n",
    "        df.to_csv(pd_file_path)\n",
    "        print('saved data, ', DCOtype, xparam, )\n",
    "    fdata.close()\n",
    "\n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_pd_redshift_from_xparam_for_total(DCOtype='BHNS', BPSmodelName='A', pathData='/Volumes/SimonsFoundation/DataDCO/', quantile_values=[0.5, 0.25, 0.75],  weights_type='merger'):\n",
    "    \"\"\"\n",
    "    whichplot='rate', 'ratio'\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print('doing total median')\n",
    "\n",
    "    redshifts_runs = obtain_redshiftsruns(pathData = pathData) # obtain redshifts that were run    \n",
    "    adjustedChannelList, DCOname = dict_channel_list[DCOtype], DCOname_dict[DCOtype]\n",
    "\n",
    "    full_data_path = pathData + alphabetDirDict[BPSmodelName] +'/COMPASCompactOutput_'+ DCOtype +'_' + BPSmodelName + '.h5'     # path for files \n",
    "    fdata = h5.File(full_data_path,'r')     # read in data \n",
    "    \n",
    "    massCO_ZAMSM1 = fdata['doubleCompactObjects']['M1'][...].squeeze()\n",
    "    massCO_ZAMSM2 = fdata['doubleCompactObjects']['M2'][...].squeeze()\n",
    "    # M1 will be the most massive, M2 the least massive compact object. \n",
    "    massCO_LVKM1, massCO_LVKM2 = obtainM1BHandM2BHassymetric(m1=fdata['doubleCompactObjects']['M1'][...].squeeze(), m2=fdata['doubleCompactObjects']['M2'][...].squeeze()) \n",
    "    MassRatioCO_LVK = massCO_LVKM2/massCO_LVKM1\n",
    "    \n",
    "    channels = fdata['doubleCompactObjects']['formaton channel'][...].squeeze()\n",
    "    weights_ =  fdata['doubleCompactObjects']['weight'][...].squeeze()\n",
    "    \n",
    "    xparams_to_run = ['t_delay'] #, 'mass_2_LVK',  'mass_tot', 't_delay', 'mass_ratio_LVK', 'qZAMS', 'separationInitial', 'M1ZAMS', 'M2ZAMS']\n",
    "    for xparam in xparams_to_run: \n",
    "\n",
    "        pd_file_path = './formation_median/'+ xparam + '_' + DCOtype + '_' + BPSmodelName + '_' + xparam + '_w_' + weights_type + 'total.csv'\n",
    "\n",
    "        # make this a dictionary instead !!\n",
    "        if xparam=='chirp_mass_LVK':\n",
    "            param_x = chirpmass(massCO_LVKM1, massCO_LVKM2)\n",
    "        elif xparam=='mass_tot':\n",
    "            param_x = massCO_LVKM1 + massCO_LVKM2\n",
    "        elif xparam=='mass_ratio_LVK':\n",
    "            param_x = MassRatioCO_LVK\n",
    "        elif xparam=='mass_1_LVK':\n",
    "            param_x = massCO_LVKM1\n",
    "        elif xparam=='mass_2_LVK':\n",
    "            param_x = massCO_LVKM2\n",
    "        elif xparam=='log10_t_delay':\n",
    "            param_x = (fdata['doubleCompactObjects']['tform'][...].squeeze() +  fdata['doubleCompactObjects']['tc'][...].squeeze() ) / 1000 # divide by 1000 to make it in [Gyr]\n",
    "            param_x = np.log10(param_x)\n",
    "        elif xparam=='t_delay':\n",
    "            param_x = (fdata['doubleCompactObjects']['tform'][...].squeeze() +  fdata['doubleCompactObjects']['tc'][...].squeeze() ) / 1000 # divide by 1000 to make it in [Gyr]\n",
    "        elif xparam=='M1ZAMS':\n",
    "            param_x = fdata['doubleCompactObjects']['M1ZAMS'][...].squeeze()\n",
    "        elif xparam=='M2ZAMS':\n",
    "            param_x = fdata['doubleCompactObjects']['M2ZAMS'][...].squeeze()\n",
    "        elif xparam=='qZAMS':\n",
    "            param_x = fdata['doubleCompactObjects']['M2ZAMS'][...].squeeze() / fdata['doubleCompactObjects']['M1ZAMS'][...].squeeze()\n",
    "        elif xparam=='separationInitial':\n",
    "            param_x = fdata['doubleCompactObjects']['separationInitial'][...].squeeze()\n",
    "\n",
    "\n",
    "        nZ = len(redshifts_runs)\n",
    "        fc_data = np.zeros((nZ, 1)) # create empty dataset for redshifts \n",
    "        fc_data[:,0] = np.round(redshifts_runs,4)  # fill with redshift data rounded to 4 digits \n",
    "        df = pd.DataFrame(fc_data, columns=[\"redshift\"])\n",
    "\n",
    "        \n",
    "\n",
    "#         for ind_mssfr, mssfr in enumerate([MSSFRnameslist[1]]):\n",
    "        for ind_mssfr, mssfr in enumerate(MSSFRnameslist[1:3]):\n",
    "\n",
    "            median_at_redshifts = np.zeros_like(redshifts_runs)\n",
    "\n",
    "            data_to_add = np.zeros((nZ, len(quantile_values)))\n",
    "            data_to_add[:] = np.nan # start with nan values so that we do not plot datapoint if it doesnt exist \n",
    "            column_names = ['all_' + 'xyz_' + mssfr+ ' q_' + str(quantile_values[i]) for i in range(len(quantile_values))] # creates array with header names \n",
    "\n",
    "            for z_ind, redshift in enumerate(redshifts_runs[0:]):\n",
    "                redshift = np.round(redshift,4)\n",
    "\n",
    "                if weights_type=='merger':\n",
    "                    fparam_key = 'weights_intrinsicPerRedshift'\n",
    "                    weightheader = 'w_' + mssfr + '_z_' +  str(redshift)\n",
    "                elif weights_type=='formation':\n",
    "                    fparam_key = \"weights_intrinsicFormationPerRedshift\"\n",
    "                    weightheader = 'wform_' + mssfr + '_z_' +  str(redshift)\n",
    "                weights_ = fdata[fparam_key][weightheader][...].squeeze()    \n",
    "\n",
    "                # we do not care about the very small rates, keep those to zero (nan)\n",
    "                if np.sum(weights_)>1E-4: \n",
    "                    data_to_add[z_ind] = weighted_quantile(values=param_x, quantiles=quantile_values, sample_weight=weights_)\n",
    "\n",
    "            df_to_add = pd.DataFrame(data_to_add, columns=column_names)\n",
    "            df = pd.concat([df, df_to_add], axis=1)        \n",
    "\n",
    "\n",
    "        df.to_csv(pd_file_path)\n",
    "        print('saved data, ', DCOtype, xparam, )\n",
    "    fdata.close()\n",
    "\n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################ CHANGE THE THINGS BELOW ################\n",
    "quantile_values=[0.5, 0.25, 0.75, 0.1, 0.9]\n",
    "DCOTypeList = ['BBH'] #, 'BHNS'] #['BHNS', 'BNS', 'BBH'] #, https://arxiv.org/pdf/2402.00935.pdf\n",
    "pathData='/Volumes/SimonsFoundation/DataDCO/'\n",
    "single_model=True\n",
    "# only_channels_with_min_contribution = 0.01 # percent\n",
    "dict_channel_list = {'BBH':['classic', 'stable B no CEE', 'other', 'immediate CE', r'double-core CE'],\\\n",
    "                     'BHNS':['classic', 'stable B no CEE', 'other', 'immediate CE', r'double-core CE'],\\\n",
    "                     'BNS':['classic', 'stable B no CEE', 'other', 'immediate CE', r'double-core CE'] } \n",
    "weights_type= 'formation'# 'merger'# 'formation' #\n",
    "create_df_file = True\n",
    "minimum_fractional_contribution_fc = 0.05\n",
    "###########################################################\n",
    "\n",
    "\n",
    "        \n",
    "# TOTAL MEDIAN \n",
    "\n",
    "def run_create_median(RunCreatePDfilesQuantilesDCO_form_channels=False, RunCreatePDfilesQuantilesDCO_totals=False):\n",
    "\n",
    "    \n",
    "    if RunCreatePDfilesQuantilesDCO_form_channels==True: \n",
    "        for DCOtype in DCOTypeList:\n",
    "            print()\n",
    "            print('------------------------------')\n",
    "            print('at ',  DCOtype)\n",
    "            for ind_bps, BPSmodelName in enumerate(BPSnameslist[10:]):\n",
    "#             for ind_bps, BPSmodelName in enumerate([BPSnameslist[0]]):\n",
    "                print('at BPS model ', BPSmodelName)\n",
    "\n",
    "                df = create_pd_redshift_from_xparam_for_fc(quantile_values=quantile_values, BPSmodelName=BPSmodelName, DCOtype=DCOtype, weights_type=weights_type) #, pd_file_path=pd_file_path)\n",
    "\n",
    "    \n",
    "    \n",
    "    if RunCreatePDfilesQuantilesDCO_totals==True:\n",
    "        for DCOtype in DCOTypeList:\n",
    "            print()\n",
    "            print('------------------------------')\n",
    "            print('at ',  DCOtype)\n",
    "#             for ind_bps, BPSmodelName in enumerate([BPSnameslist[0]]):\n",
    "            for ind_bps, BPSmodelName in enumerate(BPSnameslist[10:]):\n",
    "                print('at BPS model ', BPSmodelName)\n",
    "\n",
    "                df = create_pd_redshift_from_xparam_for_total(quantile_values=quantile_values, BPSmodelName=BPSmodelName, DCOtype=DCOtype, weights_type=weights_type) #, pd_file_path=pd_file_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return print('DONE')\n",
    "\n",
    "\n",
    "# run create pandas efficiently \n",
    "run_create_median(RunCreatePDfilesQuantilesDCO_form_channels=True)\n",
    "# run totals:\n",
    "# run_create_median(RunCreatePDfilesQuantilesDCO_totals=True) \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19450027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7857a7c",
   "metadata": {},
   "source": [
    "# code to create the csv files with the medians as a function of redshift:\n",
    "\n",
    "runs for formation channel, or for total rate the medians. Might need to run again when I combine the vii channel with the only stable mass transfer channel\n",
    "\n",
    "### CHECK PYTHON script instead!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30216244",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def create_pd_redshift_from_xparam_for_fc(DCOtype='BHNS', BPSmodelName='A', pathData='/Volumes/SimonsFoundation/DataDCO/', quantile_values=[0.5, 0.25, 0.75],\\\n",
    "#                                                weights_type='merger'):\n",
    "#     \"\"\"\n",
    "#     whichplot='rate', 'ratio'\n",
    "    \n",
    "#     \"\"\"\n",
    "#     redshifts_runs = obtain_redshiftsruns(pathData = pathData) # obtain redshifts that were run    \n",
    "#     adjustedChannelList, DCOname = dict_channel_list[DCOtype], DCOname_dict[DCOtype]\n",
    "\n",
    "#     full_data_path = pathData + alphabetDirDict[BPSmodelName] +'/COMPASCompactOutput_'+ DCOtype +'_' + BPSmodelName + '.h5'     # path for files \n",
    "#     fdata = h5.File(full_data_path,'r')     # read in data \n",
    "    \n",
    "#     massCO_ZAMSM1 = fdata['doubleCompactObjects']['M1'][...].squeeze()\n",
    "#     massCO_ZAMSM2 = fdata['doubleCompactObjects']['M2'][...].squeeze()\n",
    "#     # M1 will be the most massive, M2 the least massive compact object. \n",
    "#     massCO_LVKM1, massCO_LVKM2 = obtainM1BHandM2BHassymetric(m1=fdata['doubleCompactObjects']['M1'][...].squeeze(), m2=fdata['doubleCompactObjects']['M2'][...].squeeze()) \n",
    "#     MassRatioCO_LVK = massCO_LVKM2/massCO_LVKM1\n",
    "    \n",
    "#     channels = fdata['doubleCompactObjects']['formaton channel'][...].squeeze()\n",
    "    \n",
    "#     xparams_to_run = ['t_delay']#['mass_1_LVK', 'mass_2_LVK',  'mass_tot', 't_delay', 'mass_ratio_LVK', 'qZAMS', 'separationInitial', 'M1ZAMS', 'M2ZAMS']\n",
    "#     for xparam in xparams_to_run: \n",
    "        \n",
    "#         pd_file_path = './formation_median/'+ xparam + '_' + DCOtype + '_' + BPSmodelName + '_' + xparam + '_w_' + weights_type + '.csv'\n",
    "\n",
    "#         # make this a dictionary instead !!\n",
    "#         if xparam=='chirp_mass_LVK':\n",
    "#             param_x = chirpmass(massCO_LVKM1, massCO_LVKM2)\n",
    "#         elif xparam=='mass_tot':\n",
    "#             param_x = massCO_LVKM1 + massCO_LVKM2\n",
    "#         elif xparam=='mass_ratio_LVK':\n",
    "#             param_x = MassRatioCO_LVK\n",
    "#         elif xparam=='mass_1_LVK':\n",
    "#             param_x = massCO_LVKM1\n",
    "#         elif xparam=='mass_2_LVK':\n",
    "#             param_x = massCO_LVKM2\n",
    "#         elif xparam=='log10_t_delay':\n",
    "#             param_x = (fdata['doubleCompactObjects']['tform'][...].squeeze() +  fdata['doubleCompactObjects']['tc'][...].squeeze() ) / 1000 # divide by 1000 to make it in [Gyr]\n",
    "#             param_x = np.log10(param_x)\n",
    "#         elif xparam=='t_delay':\n",
    "#             param_x = (fdata['doubleCompactObjects']['tform'][...].squeeze() +  fdata['doubleCompactObjects']['tc'][...].squeeze() ) / 1000 # divide by 1000 to make it in [Gyr]\n",
    "#         elif xparam=='M1ZAMS':\n",
    "#             param_x = fdata['doubleCompactObjects']['M1ZAMS'][...].squeeze()\n",
    "#         elif xparam=='M2ZAMS':\n",
    "#             param_x = fdata['doubleCompactObjects']['M2ZAMS'][...].squeeze()\n",
    "#         elif xparam=='qZAMS':\n",
    "#             param_x = fdata['doubleCompactObjects']['M2ZAMS'][...].squeeze() / fdata['doubleCompactObjects']['M1ZAMS'][...].squeeze()\n",
    "#         elif xparam=='separationInitial':\n",
    "#             param_x = fdata['doubleCompactObjects']['separationInitial'][...].squeeze()\n",
    "#         del massCO_ZAMSM1\n",
    "#         del massCO_ZAMSM2\n",
    "#         del massCO_LVKM2\n",
    "#         del massCO_LVKM1\n",
    "#         del MassRatioCO_LVK\n",
    "    \n",
    "#         nZ = len(redshifts_runs)\n",
    "#         fc_data = np.zeros((nZ, 1)) # create empty dataset for redshifts \n",
    "#         fc_data[:,0] = np.round(redshifts_runs,4)  # fill with redshift data rounded to 4 digits \n",
    "#         df = pd.DataFrame(fc_data, columns=[\"redshift\"])\n",
    "\n",
    "    \n",
    "#         for nrC, Channel in enumerate(adjustedChannelList): \n",
    "#             # obtain fc_mask for the requested channel name \n",
    "#             ind_wanted = dictFormationChannelIndex[Channel]\n",
    "#             mask_MRR = (channels==ind_wanted)\n",
    "\n",
    "#             for ind_mssfr, mssfr in enumerate(MSSFRnameslist[1:]):\n",
    "\n",
    "#                 median_at_redshifts = np.zeros_like(redshifts_runs)\n",
    "\n",
    "#                 data_to_add = np.zeros((nZ, len(quantile_values)))\n",
    "#                 data_to_add[:] = np.nan # start with nan values so that we do not plot datapoint if it doesnt exist \n",
    "\n",
    "#                 column_names = [Channel + 'xyz_' + mssfr+ ' q_' + str(quantile_values[i]) for i in range(len(quantile_values))] # creates array with header names \n",
    "\n",
    "#                 for z_ind, redshift in enumerate(redshifts_runs[:]):\n",
    "#                     redshift = np.round(redshift,4)\n",
    "\n",
    "#                     if weights_type=='merger':\n",
    "#                         fparam_key = 'weights_intrinsicPerRedshift'\n",
    "#                         weightheader = 'w_' + mssfr + '_z_' +  str(redshift)\n",
    "#                     elif weights_type=='formation':\n",
    "#                         fparam_key = \"weights_intrinsicFormationPerRedshift\"\n",
    "#                         weightheader = 'wform_' + mssfr + '_z_' +  str(redshift)\n",
    "#                     weights_ = fdata[fparam_key][weightheader][...].squeeze()    \n",
    "                    \n",
    "                    \n",
    "#                     # we do not care about the very small rates, so do not report medians for formation channels at redshifts that dont pass the minimum channel contribution\n",
    "#                     if np.sum(weights_)>1E-4:  # and we dont want to calculate medians when the total rate is just super low \n",
    "#                         fractional_contribution_fc = np.sum(weights_[mask_MRR])/np.sum(weights_) # contribution of the channel at this redshift \n",
    "#                         if fractional_contribution_fc>=minimum_fractional_contribution_fc: \n",
    "#                             data_to_add[z_ind] = weighted_quantile(values=param_x[mask_MRR], quantiles=quantile_values, sample_weight=weights_[mask_MRR])\n",
    "# #                     else:\n",
    "# #                         print('skipping channel', Channel, ' because fractional contribution is ', fractional_contribution_fc)\n",
    "\n",
    "                        \n",
    "#                 df_to_add = pd.DataFrame(data_to_add, columns=column_names)\n",
    "#                 df = pd.concat([df, df_to_add], axis=1)        \n",
    "        \n",
    "\n",
    "#         df.to_csv(pd_file_path)\n",
    "#         print('saved data, ', DCOtype, xparam, )\n",
    "#     fdata.close()\n",
    "\n",
    "#     return \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def create_pd_redshift_from_xparam_for_total(DCOtype='BHNS', BPSmodelName='A', pathData='/Volumes/SimonsFoundation/DataDCO/', quantile_values=[0.5, 0.25, 0.75],  weights_type='merger'):\n",
    "#     \"\"\"\n",
    "#     whichplot='rate', 'ratio'\n",
    "    \n",
    "#     \"\"\"\n",
    "    \n",
    "#     print('doing total median')\n",
    "\n",
    "#     redshifts_runs = obtain_redshiftsruns(pathData = pathData) # obtain redshifts that were run    \n",
    "#     adjustedChannelList, DCOname = dict_channel_list[DCOtype], DCOname_dict[DCOtype]\n",
    "\n",
    "#     full_data_path = pathData + alphabetDirDict[BPSmodelName] +'/COMPASCompactOutput_'+ DCOtype +'_' + BPSmodelName + '.h5'     # path for files \n",
    "#     fdata = h5.File(full_data_path,'r')     # read in data \n",
    "    \n",
    "#     massCO_ZAMSM1 = fdata['doubleCompactObjects']['M1'][...].squeeze()\n",
    "#     massCO_ZAMSM2 = fdata['doubleCompactObjects']['M2'][...].squeeze()\n",
    "#     # M1 will be the most massive, M2 the least massive compact object. \n",
    "#     massCO_LVKM1, massCO_LVKM2 = obtainM1BHandM2BHassymetric(m1=fdata['doubleCompactObjects']['M1'][...].squeeze(), m2=fdata['doubleCompactObjects']['M2'][...].squeeze()) \n",
    "#     MassRatioCO_LVK = massCO_LVKM2/massCO_LVKM1\n",
    "    \n",
    "#     channels = fdata['doubleCompactObjects']['formaton channel'][...].squeeze()\n",
    "#     weights_ =  fdata['doubleCompactObjects']['weight'][...].squeeze()\n",
    "    \n",
    "#     xparams_to_run = ['t_delay'] #, 'mass_2_LVK',  'mass_tot', 't_delay', 'mass_ratio_LVK', 'qZAMS', 'separationInitial', 'M1ZAMS', 'M2ZAMS']\n",
    "#     for xparam in xparams_to_run: \n",
    "\n",
    "#         pd_file_path = './formation_median/'+ xparam + '_' + DCOtype + '_' + BPSmodelName + '_' + xparam + '_w_' + weights_type + 'total.csv'\n",
    "\n",
    "#         # make this a dictionary instead !!\n",
    "#         if xparam=='chirp_mass_LVK':\n",
    "#             param_x = chirpmass(massCO_LVKM1, massCO_LVKM2)\n",
    "#         elif xparam=='mass_tot':\n",
    "#             param_x = massCO_LVKM1 + massCO_LVKM2\n",
    "#         elif xparam=='mass_ratio_LVK':\n",
    "#             param_x = MassRatioCO_LVK\n",
    "#         elif xparam=='mass_1_LVK':\n",
    "#             param_x = massCO_LVKM1\n",
    "#         elif xparam=='mass_2_LVK':\n",
    "#             param_x = massCO_LVKM2\n",
    "#         elif xparam=='log10_t_delay':\n",
    "#             param_x = (fdata['doubleCompactObjects']['tform'][...].squeeze() +  fdata['doubleCompactObjects']['tc'][...].squeeze() ) / 1000 # divide by 1000 to make it in [Gyr]\n",
    "#             param_x = np.log10(param_x)\n",
    "#         elif xparam=='t_delay':\n",
    "#             param_x = (fdata['doubleCompactObjects']['tform'][...].squeeze() +  fdata['doubleCompactObjects']['tc'][...].squeeze() ) / 1000 # divide by 1000 to make it in [Gyr]\n",
    "#         elif xparam=='M1ZAMS':\n",
    "#             param_x = fdata['doubleCompactObjects']['M1ZAMS'][...].squeeze()\n",
    "#         elif xparam=='M2ZAMS':\n",
    "#             param_x = fdata['doubleCompactObjects']['M2ZAMS'][...].squeeze()\n",
    "#         elif xparam=='qZAMS':\n",
    "#             param_x = fdata['doubleCompactObjects']['M2ZAMS'][...].squeeze() / fdata['doubleCompactObjects']['M1ZAMS'][...].squeeze()\n",
    "#         elif xparam=='separationInitial':\n",
    "#             param_x = fdata['doubleCompactObjects']['separationInitial'][...].squeeze()\n",
    "\n",
    "\n",
    "#         nZ = len(redshifts_runs)\n",
    "#         fc_data = np.zeros((nZ, 1)) # create empty dataset for redshifts \n",
    "#         fc_data[:,0] = np.round(redshifts_runs,4)  # fill with redshift data rounded to 4 digits \n",
    "#         df = pd.DataFrame(fc_data, columns=[\"redshift\"])\n",
    "\n",
    "        \n",
    "\n",
    "# #         for ind_mssfr, mssfr in enumerate([MSSFRnameslist[1]]):\n",
    "#         for ind_mssfr, mssfr in enumerate(MSSFRnameslist[1:3]):\n",
    "\n",
    "#             median_at_redshifts = np.zeros_like(redshifts_runs)\n",
    "\n",
    "#             data_to_add = np.zeros((nZ, len(quantile_values)))\n",
    "#             data_to_add[:] = np.nan # start with nan values so that we do not plot datapoint if it doesnt exist \n",
    "#             column_names = ['all_' + 'xyz_' + mssfr+ ' q_' + str(quantile_values[i]) for i in range(len(quantile_values))] # creates array with header names \n",
    "\n",
    "#             for z_ind, redshift in enumerate(redshifts_runs[0:]):\n",
    "#                 redshift = np.round(redshift,4)\n",
    "\n",
    "#                 if weights_type=='merger':\n",
    "#                     fparam_key = 'weights_intrinsicPerRedshift'\n",
    "#                     weightheader = 'w_' + mssfr + '_z_' +  str(redshift)\n",
    "#                 elif weights_type=='formation':\n",
    "#                     fparam_key = \"weights_intrinsicFormationPerRedshift\"\n",
    "#                     weightheader = 'wform_' + mssfr + '_z_' +  str(redshift)\n",
    "#                 weights_ = fdata[fparam_key][weightheader][...].squeeze()    \n",
    "\n",
    "#                 # we do not care about the very small rates, keep those to zero (nan)\n",
    "#                 if np.sum(weights_)>1E-4: \n",
    "#                     data_to_add[z_ind] = weighted_quantile(values=param_x, quantiles=quantile_values, sample_weight=weights_)\n",
    "\n",
    "#             df_to_add = pd.DataFrame(data_to_add, columns=column_names)\n",
    "#             df = pd.concat([df, df_to_add], axis=1)        \n",
    "\n",
    "\n",
    "#         df.to_csv(pd_file_path)\n",
    "#         print('saved data, ', DCOtype, xparam, )\n",
    "#     fdata.close()\n",
    "\n",
    "#     return \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ################ CHANGE THE THINGS BELOW ################\n",
    "# quantile_values=[0.5, 0.25, 0.75, 0.1, 0.9]\n",
    "# DCOTypeList = ['BBH'] #, 'BHNS'] #['BHNS', 'BNS', 'BBH'] #, https://arxiv.org/pdf/2402.00935.pdf\n",
    "# pathData='/Volumes/SimonsFoundation/DataDCO/'\n",
    "# single_model=True\n",
    "# # only_channels_with_min_contribution = 0.01 # percent\n",
    "# dict_channel_list = {'BBH':['classic', 'stable B no CEE', 'other', 'immediate CE'],\\\n",
    "#                      'BHNS':['classic', 'stable B no CEE', 'immediate CE'],\\\n",
    "#                      'BNS':['classic', 'stable B no CEE',  r'double-core CE', 'immediate CE', 'vii', 'vi', 'other'] } \n",
    "# weights_type= 'formation'# 'merger'# 'formation' #\n",
    "# create_df_file = True\n",
    "# minimum_fractional_contribution_fc = 0.05\n",
    "# ###########################################################\n",
    "\n",
    "\n",
    "        \n",
    "# # TOTAL MEDIAN \n",
    "\n",
    "# def run_create_median(RunCreatePDfilesQuantilesDCO_form_channels=False, RunCreatePDfilesQuantilesDCO_totals=False):\n",
    "\n",
    "    \n",
    "#     if RunCreatePDfilesQuantilesDCO_form_channels==True: \n",
    "#         for DCOtype in DCOTypeList:\n",
    "#             print()\n",
    "#             print('------------------------------')\n",
    "#             print('at ',  DCOtype)\n",
    "#             for ind_bps, BPSmodelName in enumerate(BPSnameslist):\n",
    "# #             for ind_bps, BPSmodelName in enumerate([BPSnameslist[0]]):\n",
    "#                 print('at BPS model ', BPSmodelName)\n",
    "\n",
    "#                 df = create_pd_redshift_from_xparam_for_fc(quantile_values=quantile_values, BPSmodelName=BPSmodelName, DCOtype=DCOtype, weights_type=weights_type) #, pd_file_path=pd_file_path)\n",
    "\n",
    "    \n",
    "    \n",
    "#     if RunCreatePDfilesQuantilesDCO_totals==True:\n",
    "#         for DCOtype in DCOTypeList:\n",
    "#             print()\n",
    "#             print('------------------------------')\n",
    "#             print('at ',  DCOtype)\n",
    "#             for ind_bps, BPSmodelName in enumerate([BPSnameslist[0]]):\n",
    "# #             for ind_bps, BPSmodelName in enumerate(BPSnameslist):\n",
    "#                 print('at BPS model ', BPSmodelName)\n",
    "\n",
    "#                 df = create_pd_redshift_from_xparam_for_total(quantile_values=quantile_values, BPSmodelName=BPSmodelName, DCOtype=DCOtype, weights_type=weights_type) #, pd_file_path=pd_file_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     return print('DONE')\n",
    "\n",
    "\n",
    "# # run create pandas efficiently \n",
    "# run_create_median(RunCreatePDfilesQuantilesDCO_form_channels=True, RunCreatePDfilesQuantilesDCO_totals=False )#True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43ae56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bba7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93d5a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d5117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run create pandas efficiently \n",
    "run_create_median(RunCreatePDfilesQuantilesDCO_form_channels=False, RunCreatePDfilesQuantilesDCO_totals=True )#True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f37b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ CHANGE THE THINGS BELOW ################\n",
    "quantile_values=[0.5, 0.25, 0.75, 0.1, 0.9]\n",
    "DCOTypeList = ['BBH'] #, 'BHNS'] #['BHNS', 'BNS', 'BBH'] #, https://arxiv.org/pdf/2402.00935.pdf\n",
    "pathData='/Volumes/SimonsFoundation/DataDCO/'\n",
    "single_model=True\n",
    "# only_channels_with_min_contribution = 0.01 # percent\n",
    "dict_channel_list = {'BBH':['classic', 'stable B no CEE'],\\\n",
    "                     'BHNS':['classic', 'stable B no CEE', 'immediate CE'],\\\n",
    "                     'BNS':['classic', 'stable B no CEE',  r'double-core CE', 'immediate CE', 'vii', 'vi', 'other'] } \n",
    "weights_type='formation' #\n",
    "create_df_file = True\n",
    "minimum_fractional_contribution_fc = 0.05\n",
    "###########################################################\n",
    "\n",
    "\n",
    "        \n",
    "# TOTAL MEDIAN \n",
    "\n",
    "def run_create_median(RunCreatePDfilesQuantilesDCO_form_channels=False, RunCreatePDfilesQuantilesDCO_totals=False):\n",
    "\n",
    "    \n",
    "    if RunCreatePDfilesQuantilesDCO_form_channels==True: \n",
    "        for DCOtype in DCOTypeList:\n",
    "            print()\n",
    "            print('------------------------------')\n",
    "            print('at ',  DCOtype)\n",
    "#             for ind_bps, BPSmodelName in enumerate(BPSnameslist):\n",
    "            for ind_bps, BPSmodelName in enumerate(BPSnameslist[:]):\n",
    "                print('at BPS model ', BPSmodelName)\n",
    "\n",
    "                df = create_pd_redshift_from_xparam_for_fc(quantile_values=quantile_values, BPSmodelName=BPSmodelName, DCOtype=DCOtype, weights_type=weights_type) #, pd_file_path=pd_file_path)\n",
    "\n",
    "    \n",
    "    \n",
    "    if RunCreatePDfilesQuantilesDCO_totals==True:\n",
    "        for DCOtype in DCOTypeList:\n",
    "            print()\n",
    "            print('------------------------------')\n",
    "            print('at ',  DCOtype)\n",
    "            for ind_bps, BPSmodelName in enumerate(BPSnameslist[:]):\n",
    "#             for ind_bps, BPSmodelName in enumerate(BPSnameslist):\n",
    "                print('at BPS model ', BPSmodelName)\n",
    "\n",
    "                df = create_pd_redshift_from_xparam_for_total(quantile_values=quantile_values, BPSmodelName=BPSmodelName, DCOtype=DCOtype, weights_type=weights_type) #, pd_file_path=pd_file_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return print('DONE')\n",
    "\n",
    "\n",
    "# run create pandas efficiently \n",
    "run_create_median(RunCreatePDfilesQuantilesDCO_form_channels=True, RunCreatePDfilesQuantilesDCO_totals=False )#True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf441a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ed588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0306956f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc98f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183fe096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c914fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee865ddf",
   "metadata": {},
   "source": [
    "# The following code doesnt do it as efficiently but is used for plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb1c65a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def plot_xparam_formation_channels_redshift_for_quantiles(axe='None', DCOtype='BHNS', BPS_models_to_run_list=['A'], \n",
    "                                                  pathData='/Volumes/SimonsFoundation/DataDCO/',\\\n",
    "                                                mask_specific_mssfr=None,\\\n",
    "                                                whichQuantity='median', value_for_fraction=False, \\\n",
    "                                              add_model_label=True, quantile_values=[0.5, 0.25, 0.75], xparam='log10_t_delay' , weights_type='merger', single_model=True):\n",
    "    \n",
    "    \n",
    "    \n",
    "    adjustedChannelList, DCOname = dict_channel_list[DCOtype], DCOname_dict[DCOtype]\n",
    "    \n",
    "    \n",
    "    for ind_bps, BPSmodelName in enumerate(BPS_models_to_run_list):\n",
    "        pd_file_path = './formation_median/'+ xparam_wanted + '_' + DCOtype + '_' + BPSmodelName + '_' + xparam_wanted + '_w_' + weights_type + '.csv'\n",
    "        \n",
    "#         if create_df_file==True: df = create_pd_redshift_from_xparam(quantile_values=quantile_values, BPSmodelName=BPSmodelName, DCOtype=DCOtype, xparam=xparam, weights_type=weights_type, pd_file_path=pd_file_path)\n",
    "        df = pd.read_csv(pd_file_path)\n",
    "        redshifts = df[\"redshift\"]\n",
    "        \n",
    "        \n",
    "\n",
    "        # plot the channel \n",
    "        for nrC, Channel in enumerate(adjustedChannelList): \n",
    "            for ind_mssfr, mssfr in enumerate(MSSFRnameslist[2:]):\n",
    "#             for ind_mssfr, mssfr in enumerate([MSSFRnameslist[1]]):\n",
    "            \n",
    "                c_FC = channelColorDict[Channel]\n",
    "                colors_lighter_FC =  channelColorDict_lighter[Channel]\n",
    "\n",
    "                column_names = [Channel + 'xyz_' + mssfr+ ' q_' + str(quantile_values[i]) for i in range(len(quantile_values))] # creates array with header names \n",
    "                qvalues = [df[column_names[i]] for i in range(len(quantile_values))]\n",
    "\n",
    "                axe.scatter((redshifts), qvalues[0].values, color=c_FC, marker=dictMarkerShape[BPSmodelName], s=40) #/norm_classic_tdelay\n",
    "                axe.plot(   (redshifts), qvalues[0].values, color=c_FC, lw=4) #, ls=linestyles_mssfrind[ind_mssfr_zind])\n",
    "                \n",
    "#                 if len(quantile_values)>1: # if more than one quantile (median) is given, plot the other quantiles as filled between \n",
    "#                     axe.fill_between((redshifts), y1=qvalues[1], y2=qvalues[0], color=colors_lighter_FC, alpha=0.5)\n",
    "#                     axe.fill_between((redshifts), y1=qvalues[0], y2=qvalues[2], color=colors_lighter_FC, alpha=0.5)\n",
    "\n",
    "#                     axe.fill_between((redshifts), y1=qvalues[3], y2=qvalues[1], color=colors_lighter_FC, alpha=0.2)\n",
    "#                     axe.fill_between((redshifts), y1=qvalues[2], y2=qvalues[4], color=colors_lighter_FC, alpha=0.2)\n",
    "\n",
    "\n",
    "\n",
    "    xlabel = r'\\textbf{redshift} $z$'\n",
    "    \n",
    "    if xparam=='chirp_mass_LVK':\n",
    "        ylabel = r'$\\mathcal{M}_{\\rm{c}} \\ [M_{\\odot}]$'\n",
    "    elif xparam=='mass_tot':\n",
    "        ylabel = r'$\\rm{M}_{\\rm{tot}} \\ [M_{\\odot}]$'\n",
    "    elif xparam=='mass_ratio_LVK':\n",
    "        ylabel = r'$q$'\n",
    "    elif xparam=='mass_1_LVK':\n",
    "        ylabel = r'$m_1 [M_{\\odot}]$'\n",
    "    elif xparam=='mass_2_LVK':\n",
    "        ylabel = r'$m_2 [M_{\\odot}]$'\n",
    "    elif xparam=='log10_t_delay':\n",
    "        ylabel = r'$\\log_{10} t_{\\rm{delay}} \\ [\\rm{Gyr}]$'\n",
    "    elif xparam=='t_delay':\n",
    "        ylabel = r'$t_{\\rm{delay}} \\ [\\rm{Gyr}]$'\n",
    "    elif xparam=='M1ZAMS':\n",
    "        ylabel = r'$\\rm{M}_{\\rm{ZAMS, 1}} \\ [M_{\\odot}]$'\n",
    "    elif xparam=='M2ZAMS':\n",
    "        ylabel = r'$\\rm{M}_{\\rm{ZAMS, 2}} \\ [M_{\\odot}]$'\n",
    "    elif xparam=='qZAMS':\n",
    "        ylabel = r'${q}_{\\rm{ZAMS}} $'\n",
    "    elif xparam=='separationInitial':\n",
    "        ylabel = r'${a}_{\\rm{ZAMS}} [\\rm{AU}] $'      \n",
    "    \n",
    "\n",
    "    # axes properties \n",
    "    axe = layoutAxes(axe, nameX=xlabel, nameY=ylabel, setMinor=True)\n",
    "    axe.set_xlim(0,9.7)  # redshift range \n",
    "    if xparam in ['t_delay', 'separationInitial']:\n",
    "        axe.set_yscale('log')\n",
    "    \n",
    "    ## add label in a legend for plot \n",
    "    if single_model==True: annotate_label = r'\\textbf{model %s:}'%(BPSmodelName) +'\\n' + alphabetPhysicalNameDict[BPSmodelName]\n",
    "    else: annotate_label = r'\\textbf{%s}'%(DCOtype)        \n",
    "    bbox_props = dict(boxstyle=\"round\", fc=\"w\", ec=\"0.5\", alpha=0.95)\n",
    "    axe.annotate(annotate_label, xy=(0.042, .95), xycoords='axes fraction', fontsize = fs-6, weight = 'bold', ha='left', va=\"top\",bbox=bbox_props, zorder=100)             \n",
    "            \n",
    "            \n",
    "            \n",
    "    return axe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d13004",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "################ CHANGE THE THINGS BELOW ################\n",
    "quantile_values=[0.5, 0.25, 0.75, 0.1, 0.9 ]\n",
    "DCOTypeList = ['BNS']#['BHNS', 'BNS', 'BBH'] #, https://arxiv.org/pdf/2402.00935.pdf\n",
    "pathData='/Volumes/SimonsFoundation/DataDCO/'\n",
    "single_model=True\n",
    "dict_channel_list = {'BBH':['classic', 'stable B no CEE'],\\\n",
    "                     'BHNS':['classic', 'stable B no CEE', 'immediate CE'],\\\n",
    "                     'BNS':['classic', r'double-core CE', 'other'] } \n",
    "weights_type='merger'# 'formation' #\n",
    "# create_df_file = True  # create it in seperate function that is provided earlier on. \n",
    "BPSmodelName='A'\n",
    "###########################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for xparam_wanted in [ 'mass_tot', 't_delay', 'mass_ratio_LVK', 'mass_1_LVK', 'mass_2_LVK','chirp_mass_LVK','qZAMS', 'separationInitial''mass_1_LVK', 'mass_2_LVK']:  't_delay', 'mass_ratio_LVK', 'qZAMS', 'chirp_mass_LVK'\n",
    "for xparam_wanted in ['mass_1_LVK']:  #[ 'mass_tot',  'mass_ratio_LVK', 'qZAMS', 'separationInitial', 't_delay','M1ZAMS', 'M2ZAMS','t_delay']:  #'t_delay', 'mass_ratio_LVK', 'qZAMS',]: # , 'mass_ratio_LVK', 'qZAMS', 'separationInitial', 'M1ZAMS', 'M2ZAMS', 'mass_1_LVK', 'mass_2_LVK']: #, 'M1ZAMS', 'M2ZAMS']:\n",
    "    print('at xparam ', xparam_wanted)\n",
    "    \n",
    "    if single_model==True:enumerate_list = BPSnameslist[:]\n",
    "    else: enumerate_list = [0]\n",
    "    for ind_m, BPSmodelName in  enumerate(enumerate_list):\n",
    "        if single_model==True:\n",
    "            BPS_models_to_run_list=[BPSmodelName]\n",
    "            print('at BPS model ', BPSmodelName)\n",
    "            save_fig_string = BPSmodelName\n",
    "        else: \n",
    "            BPS_models_to_run_list = BPSnameslist\n",
    "            save_fig_string = 'all'\n",
    "            \n",
    "        for DCOtype in DCOTypeList: #'BNS', 'BHNS', \n",
    "            print('at DCOtype =', DCOtype)\n",
    "\n",
    "\n",
    "            ncols, nrows= 1,1\n",
    "            f, ax= plt.subplots(ncols=ncols,nrows=nrows,figsize=(10,6), gridspec_kw={\"width_ratios\":1.5*np.ones(ncols), \"height_ratios\":1*np.ones(nrows)})\n",
    "\n",
    "            ax = plot_xparam_formation_channels_redshift_for_quantiles(axe=ax, DCOtype=DCOtype, BPS_models_to_run_list=BPS_models_to_run_list,\\\n",
    "                                                                  pathData=pathData,  single_model=single_model, quantile_values=quantile_values,\\\n",
    "                                                                               xparam=xparam_wanted, weights_type=weights_type) \n",
    "\n",
    "\n",
    "            \n",
    "            ##  SAVE FIG  ###\n",
    "            plt.tight_layout()\n",
    "            plt.subplots_adjust(wspace=0., hspace=0.18)  \n",
    "            plt.savefig('./formation_median/'+ xparam_wanted + '/zQuantile_' +  DCOtype + '_' + save_fig_string + '_' + xparam_wanted + '_w_' + weights_type + '.png', transparent=False, dpi=300)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee78d7e2",
   "metadata": {},
   "source": [
    "## only make plots of existing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8688d5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BPSnameslist)\n",
    "print(BPSnameslistslistslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67302285",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################ CHANGE THE THINGS BELOW ################\n",
    "quantile_values=[0.5] #, 0.25, 0.75, 0.1, 0.9 ]\n",
    "DCOTypeList = ['BHNS', 'BNS'] #, https://arxiv.org/pdf/2402.00935.pdf\n",
    "pathData='/Volumes/SimonsFoundation/DataDCO/'\n",
    "single_model=False # True ; we want all models in one plot :) \n",
    "only_channels_with_min_contribution = 0.01 # percent\n",
    "dict_channel_list = {'BBH':['classic', 'stable B no CEE'],\\\n",
    "                     'BHNS':['classic', 'stable B no CEE', 'immediate CE'],\\\n",
    "                     'BNS':['classic', r'double-core CE', 'other'] } \n",
    "weights_type='formation' #'merger'\n",
    "create_df_file = False ## !! This is important if you only want to run the existing data \n",
    "###########################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for xparam_wanted in [ 'mass_tot', 't_delay', 'mass_ratio_LVK', 'mass_1_LVK', 'mass_2_LVK','chirp_mass_LVK','qZAMS', 'separationInitial']:  't_delay', 'mass_ratio_LVK', 'qZAMS', \n",
    "for xparam_wanted in [ 't_delay']: # , 'mass_ratio_LVK', 'qZAMS', 'separationInitial', 'M1ZAMS', 'M2ZAMS', 'mass_1_LVK', 'mass_2_LVK']: #, 'M1ZAMS', 'M2ZAMS']:\n",
    "    print('at xparam ', xparam_wanted)\n",
    "    \n",
    "    if single_model==True:enumerate_list = BPSnameslist[:].remove('E')\n",
    "    else: enumerate_list = [0]\n",
    "    for ind_m, BPSmodelName in  enumerate(enumerate_list): # I dont want to work with model E anymore \n",
    "        if single_model==True:\n",
    "            BPS_models_to_run_list=[BPSmodelName]\n",
    "            print('at BPS model ', BPSmodelName)\n",
    "            save_fig_string = BPSmodelName\n",
    "        else: \n",
    "            BPS_models_to_run_list = BPSnameslist\n",
    "            print(BPSnameslist)\n",
    "            BPS_models_to_run_list #.remove('E') # I dont want to work with model E anymore \n",
    "            save_fig_string = 'all'\n",
    "        \n",
    "        \n",
    "        for DCOtype in DCOTypeList: #'BNS', 'BHNS', \n",
    "            print('at DCOtype =', DCOtype)\n",
    "\n",
    "\n",
    "\n",
    "            ncols, nrows= 1,1\n",
    "            f, ax= plt.subplots(ncols=ncols,nrows=nrows,figsize=(10,6), gridspec_kw={\"width_ratios\":1.5*np.ones(ncols), \"height_ratios\":1*np.ones(nrows)})            \n",
    "\n",
    "            ax = plot_xparam_formation_channels_redshift_for_quantiles(axe=ax, DCOtype=DCOtype, BPS_models_to_run_list=BPS_models_to_run_list,\\\n",
    "                                                                  pathData=pathData,  single_model=single_model, quantile_values=quantile_values,\\\n",
    "                                                                               xparam=xparam_wanted, weights_type=weights_type, create_df_file=create_df_file) \n",
    "\n",
    "\n",
    "            \n",
    "            ##  SAVE FIG  ###\n",
    "            plt.tight_layout()\n",
    "            plt.subplots_adjust(wspace=0., hspace=0.18)  \n",
    "            plt.savefig('./formation_median/'+ xparam_wanted + '/zQuantile_' +  DCOtype + '_' + save_fig_string + '_' + xparam_wanted + '_w_' + weights_type + '.png', transparent=False, dpi=300)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            print()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d4c65d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a37dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ab140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f363b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969cce3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948a2854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea890d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe7cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8714231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c5b828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04afa101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26023a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087475df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fab67a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92e506cd",
   "metadata": {},
   "source": [
    "## ENDS HERE ## \n",
    "GO TO other jupyter notebook (in same folder) for the working/most recent version of code as a function of metallicity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70166baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "adsga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e612350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1f0fa44",
   "metadata": {},
   "source": [
    "# as a function of metallicity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae6452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11229940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_formation_channels_metallicity_xparam(axe='None', DCOtype='BHNS', \\\n",
    "                                          xparam='mass_tot', BPSmodelName='A', \n",
    "                                                  pathData='/Volumes/SimonsFoundation/DataDCO/',\\\n",
    "                                                mask_specific_mssfr=None,\\\n",
    "                                                whichQuantity='median', value_for_fraction=False):\n",
    "    \"\"\"\n",
    "    whichplot='rate', 'ratio'\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    pathData='/Volumes/SimonsFoundation/DataDCO/' # path to datafiles \n",
    "    redshifts_runs = obtain_redshiftsruns(pathData = pathData) # obtain redshifts that were run     \n",
    "    adjustedChannelList = ['classic', 'stable B no CEE'] #, 'vii', 'immediate CE',  r'double-core CE', 'other']\n",
    "    DCOname = DCOname_dict[DCOtype]\n",
    "\n",
    "    # path for files \n",
    "    full_data_path = pathData + alphabetDirDict[BPSmodelName] +'/COMPASCompactOutput_'+ DCOtype +'_' + BPSmodelName + '.h5'\n",
    "\n",
    "    # read in data \n",
    "    fdata = h5.File(full_data_path,'r')\n",
    "    \n",
    "    # get the delay time in Gyr \n",
    "#     param_x = (fdata['doubleCompactObjects']['tform'][...].squeeze() +  fdata['doubleCompactObjects']['tc'][...].squeeze() ) / 1000 # divide by 1000 to make it in [Gyr]\n",
    "    \n",
    "    \n",
    "    massCO_ZAMSM1 = fdata['doubleCompactObjects']['M1'][...].squeeze()\n",
    "    massCO_ZAMSM2 = fdata['doubleCompactObjects']['M2'][...].squeeze()\n",
    "    # M1 will be the most massive, M2 the least massive compact object. \n",
    "    massCO_LVKM1, massCO_LVKM2 = obtainM1BHandM2BHassymetric(m1=fdata['doubleCompactObjects']['M1'][...].squeeze(), m2=fdata['doubleCompactObjects']['M2'][...].squeeze()) \n",
    "    MassRatioCO_LVK = massCO_LVKM2/massCO_LVKM1\n",
    "\n",
    "    if xparam=='chirp_mass_LVK':\n",
    "        param_x = chirpmass(massCO_LVKM1, massCO_LVKM2)\n",
    "        nameX = r'$\\mathcal{M}_{\\rm{c}} \\ [M_{\\odot}]$'\n",
    "        nameY = r'\\textbf{PDF}'\n",
    "        xx = np.linspace(1,100,1000)\n",
    "    elif xparam=='mass_tot':\n",
    "        param_x = massCO_LVKM1 + massCO_LVKM2\n",
    "        nameX = r'$\\rm{M}_{\\rm{tot}} \\ [M_{\\odot}]$'\n",
    "        nameY = r'\\textbf{PDF}'\n",
    "        xx = np.linspace(1,5,1000)\n",
    "    elif xparam=='mass_ratio_LVK':\n",
    "        param_x = MassRatioCO_LVK\n",
    "        nameX = r'$q$'\n",
    "        nameY = r'\\textbf{PDF}'\n",
    "        xx = np.linspace(-0.2,1.2,1000)\n",
    "    elif xparam=='mass_1_LVK':\n",
    "        param_x = massCO_LVKM1\n",
    "        nameX = r'$m_1 [M_{\\odot}]$'\n",
    "        nameY = r'\\textbf{PDF}'\n",
    "        if DCOtype=='BBH':\n",
    "            xx = np.linspace(-1,150,1000) # needs to be a little bit larger\n",
    "        elif DCOtype=='BHNS':\n",
    "            xx = np.linspace(-1,50,1000)\n",
    "        elif DCOtype=='BNS':\n",
    "            xx = np.linspace(-2,5,500)\n",
    "    elif xparam=='mass_2_LVK':\n",
    "        param_x = massCO_LVKM2\n",
    "        nameX = r'$m_2 [M_{\\odot}]$'\n",
    "        nameY = r'\\textbf{PDF}'\n",
    "        if DCOtype=='BBH':\n",
    "            xx = np.linspace(-1,150,1000) # needs to be a little bit larger\n",
    "        elif DCOtype=='BHNS':\n",
    "            xx = np.linspace(-2,5,1000)\n",
    "        elif DCOtype=='BNS':\n",
    "            xx = np.linspace(-2,5,500)\n",
    "            \n",
    "    elif xparam=='log10_t_delay':\n",
    "        param_x = (fdata['doubleCompactObjects']['tform'][...].squeeze() +  fdata['doubleCompactObjects']['tc'][...].squeeze() ) / 1000 # divide by 1000 to make it in [Gyr]\n",
    "        param_x = np.log10(param_x)\n",
    "        nameX = r'$\\log_{10} t_{\\rm{delay}} \\ [\\rm{Gyr}]$'\n",
    "        nameY = r'\\textbf{PDF}'  \n",
    "        xx = np.linspace(-2.5,2,500)  \n",
    "        print('obtained params')\n",
    "    elif xparam=='log10_t_delay':\n",
    "        param_x = (fdata['doubleCompactObjects']['tform'][...].squeeze() +  fdata['doubleCompactObjects']['tc'][...].squeeze() ) / 1000 # divide by 1000 to make it in [Gyr]\n",
    "        param_x = np.log10(param_x)\n",
    "        nameX = r'$\\log_{10} t_{\\rm{delay}} \\ [\\rm{Gyr}]$'\n",
    "        nameY = r'\\textbf{PDF}'  \n",
    "        xx = np.linspace(-2.5,2,500)  \n",
    "        print('obtained params')    \n",
    "    \n",
    "    elif xparam=='t_delay':\n",
    "        param_x = (fdata['doubleCompactObjects']['tform'][...].squeeze() +  fdata['doubleCompactObjects']['tc'][...].squeeze() ) / 1000 # divide by 1000 to make it in [Gyr]\n",
    "        nameX = r'$\\log_{10} t_{\\rm{delay}} \\ [\\rm{Gyr}]$'\n",
    "        nameY = r'\\textbf{PDF}'  \n",
    "        xx = np.linspace(-2.5,2,500)         \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    channels = fdata['doubleCompactObjects']['formaton channel'][...].squeeze()\n",
    "    metallicities = fdata['doubleCompactObjects']['Metallicity1'][...].squeeze()\n",
    "    weights_ =  fdata['doubleCompactObjects']['weight'][...].squeeze()\n",
    "    #     param_x = np.log10(param_x)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    for nrC, Channel in enumerate(adjustedChannelList): \n",
    "#         print('now at channel: ', Channel)\n",
    "        ind_wanted = dictFormationChannelIndex[Channel]\n",
    "        # set color         \n",
    "        c_FC = channelColorDict[Channel]\n",
    "        colors_lighter_FC =  channelColorDict_lighter[Channel]\n",
    "\n",
    "\n",
    "        mask_MRR = (channels==ind_wanted)\n",
    "        \n",
    "        \n",
    "        \n",
    "        median_at_ZZ = np.zeros_like(np.unique(metallicities))\n",
    "        \n",
    "    #     for ind_mssfr, mssfr in enumerate(MSSFRnameslist[:]):\n",
    "        for ind_Z, Zvalue in enumerate(np.unique(metallicities)):\n",
    "\n",
    "            mask_ZZ = metallicities[mask_MRR]==Zvalue\n",
    "\n",
    "            \n",
    "            \n",
    "            if len(weights_[mask_MRR][mask_ZZ])>10:\n",
    "            ######## EXTRA FLUFF JUST FOR PLOTTING SOME MSSFR, NOT THE BEST CODE\n",
    "\n",
    "\n",
    "\n",
    "                if whichQuantity=='median':\n",
    "                    median_at_ZZ[ind_Z] = weighted_quantile(values=param_x[mask_MRR][mask_ZZ], quantiles=[0.5], sample_weight=weights_[mask_MRR][mask_ZZ])\n",
    "                    nameY = r'$<t_{\\rm{delay}}> \\ [\\rm{Gyr}]$'\n",
    "                elif whichQuantity=='fraction':\n",
    "                    mask_systems = param_x[mask_MRR][mask_ZZ] <= value_for_fraction\n",
    "                    median_at_ZZ[ind_Z] = np.sum(weights_[mask_MRR][mask_ZZ][mask_systems])/np.sum(weights_[mask_MRR][mask_ZZ])\n",
    "                    nameY = r'$\\rm{fraction }  t_{\\rm{delay}} < %s \\ [\\rm{Gyr}]$'%value_for_fraction\n",
    "                        \n",
    "        mask_not_zero = (median_at_ZZ!=0)\n",
    "        axe.scatter(np.log10(np.unique(metallicities))[mask_not_zero], median_at_ZZ[mask_not_zero], color=c_FC, marker=dictMarkerShape[BPSmodelName])\n",
    "        axe.plot(np.log10(np.unique(metallicities))[mask_not_zero],    median_at_ZZ[mask_not_zero], color=c_FC) #, ls=linestyles_mssfrind[ind_mssfr_zind])\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    # always close the dataset\n",
    "    fdata.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     ylabel = r'\\textbf{Rate}'\n",
    "        \n",
    "        \n",
    "    xlabel = r'\\textbf{Metallicity} \\ $Z$'\n",
    "    ylabel = nameX\n",
    "    \n",
    "    axe = layoutAxes(axe, nameX=xlabel, nameY=ylabel, setMinor=True)\n",
    "\n",
    "    \n",
    "#     axe.set_xlim(0.001,0.3)\n",
    "    if whichQuantity=='fraction':\n",
    "        axe.set_ylim(0., 1)\n",
    "\n",
    "    if xparam in ['mass_tot']:\n",
    "        axe.set_ylim(2, 4)        \n",
    "\n",
    "        \n",
    "#         axe.set_ylim(1, 1E4)\n",
    "    if whichQuantity=='median':\n",
    "        if xparam in ['t_delay']:\n",
    "            axe.set_yscale('log')\n",
    "            axe.set_ylim(0.001, 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     axe.set_xscale('log')\n",
    "    \n",
    "    \n",
    "    bbox_props = dict(boxstyle=\"round\", fc=\"w\", ec=\"0.5\", alpha=0.95)\n",
    "    axe.annotate(r'\\textbf{model %s:}'%(BPSmodelName) +'\\n' + alphabetPhysicalNameDict[BPSmodelName], xy=(0.042, .95),\\\n",
    "                 xycoords='axes fraction', fontsize = fs, weight = 'bold', ha='left', va=\"top\",bbox=bbox_props,\\\n",
    "                zorder=1E10)\n",
    "\n",
    "    return axe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plot delay times with fraction \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "whichQuantity='median'\n",
    "xparam = 't_delay'\n",
    "\n",
    "# for ind_m, BPSmodelName in  enumerate([BPSnameslist[0]]):\n",
    "for ind_m, BPSmodelName in  enumerate(BPSnameslist[:]):\n",
    "#     color_m = colorDirDict[BPSmodelName]\n",
    "    print('at BPS model ', BPSmodelName)\n",
    "\n",
    "    for DCOtype in ['BNS']:\n",
    "        print()\n",
    "        print('at DCOtype =', DCOtype)\n",
    "    #     for nrC, Channel in enumerate(adjustedChannelList): \n",
    "    #     for nrC, Channel in enumerate([adjustedChannelList[0]]): \n",
    "    #         print('now at Channel', Channel)\n",
    "\n",
    "        ncols, nrows= 1,1\n",
    "        f, ax= plt.subplots(ncols=ncols,nrows=nrows,figsize=(10,8), \n",
    "                      gridspec_kw={\"width_ratios\":1.5*np.ones(ncols), \"height_ratios\":1*np.ones(nrows)})\n",
    "\n",
    "\n",
    "\n",
    "        ax = plot_formation_channels_metallicity_xparam(axe=ax, DCOtype=DCOtype, xparam=xparam, BPSmodelName=BPSmodelName,\\\n",
    "                                                              pathData=pathData,\\\n",
    "                                                            mask_specific_mssfr=None,\\\n",
    "                                                         whichQuantity=whichQuantity, value_for_fraction=False) \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        ##  SAVE FIG  ###\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(wspace=0., hspace=0.18)  \n",
    "        plt.savefig('./formation_median/'+xparam+'/'+xparam+'_ratesMetallicity_' +  DCOtype + '_' + BPSmodelName + '_' + whichQuantity + '.png', transparent=False, dpi=300)\n",
    "        plt.savefig('./formation_median/'+xparam+'/'+xparam+'_ratesMetallicity_' +  DCOtype + '_' + BPSmodelName + '_' + whichQuantity + '.pdf', transparent=True)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "                    \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a554c8ca",
   "metadata": {},
   "source": [
    "## I am working here :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29449817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_formation_channels_metallicity_xparam(axe='None', DCOtype='BHNS', \\\n",
    "                                          BPSmodelName='A', \n",
    "                                                  pathData='/Volumes/SimonsFoundation/DataDCO/',\\\n",
    "                                                mask_specific_mssfr=None,\\\n",
    "                                                whichQuantity='median', value_for_fraction=False, \\\n",
    "                                              add_model_label=True):\n",
    "    \"\"\"\n",
    "    whichplot='rate', 'ratio'\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    pathData='/Volumes/SimonsFoundation/DataDCO/' # path to datafiles \n",
    "    redshifts_runs = obtain_redshiftsruns(pathData = pathData) # obtain redshifts that were run     \n",
    "    adjustedChannelList = ['classic', 'stable B no CEE'] #, 'vii', 'immediate CE',  r'double-core CE', 'other'\n",
    "    DCOname = DCOname_dict[DCOtype]\n",
    "\n",
    "    # path for files \n",
    "    full_data_path = pathData + alphabetDirDict[BPSmodelName] +'/COMPASCompactOutput_'+ DCOtype +'_' + BPSmodelName + '.h5'\n",
    "\n",
    "    # read in data \n",
    "    fdata = h5.File(full_data_path,'r')\n",
    "    \n",
    "    # get the delay time in Gyr \n",
    "    param_x = (fdata['doubleCompactObjects']['tform'][...].squeeze() +  fdata['doubleCompactObjects']['tc'][...].squeeze() ) / 1000 # divide by 1000 to make it in [Gyr]\n",
    "    channels = fdata['doubleCompactObjects']['formaton channel'][...].squeeze()\n",
    "    metallicities = fdata['doubleCompactObjects']['Metallicity1'][...].squeeze()\n",
    "    weights_ =  fdata['doubleCompactObjects']['weight'][...].squeeze()\n",
    "    #     param_x = np.log10(param_x)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    for nrC, Channel in enumerate(adjustedChannelList): \n",
    "#         print('now at channel: ', Channel)\n",
    "        ind_wanted = dictFormationChannelIndex[Channel]\n",
    "        # set color         \n",
    "        c_FC = channelColorDict[Channel]\n",
    "        colors_lighter_FC =  channelColorDict_lighter[Channel]\n",
    "\n",
    "\n",
    "        mask_MRR = (channels==ind_wanted)\n",
    "        \n",
    "        \n",
    "        \n",
    "        median_at_ZZ = np.zeros_like(np.unique(metallicities))\n",
    "        \n",
    "    #     for ind_mssfr, mssfr in enumerate(MSSFRnameslist[:]):\n",
    "        for ind_Z, Zvalue in enumerate(np.unique(metallicities)):\n",
    "\n",
    "            mask_ZZ = metallicities[mask_MRR]==Zvalue\n",
    "\n",
    "            \n",
    "            \n",
    "            if len(weights_[mask_MRR][mask_ZZ])>10:\n",
    "            ######## EXTRA FLUFF JUST FOR PLOTTING SOME MSSFR, NOT THE BEST CODE\n",
    "\n",
    "\n",
    "\n",
    "                if whichQuantity=='median':\n",
    "                    quantiles = weighted_quantile(values=param_x[mask_MRR][mask_ZZ], quantiles=[0.5, 0.25, 0.75], sample_weight=weights_[mask_MRR][mask_ZZ])\n",
    "                    median_at_ZZ[ind_Z] = quantiles[0] # first requested value is the median\n",
    "                    nameY = r'$<t_{\\rm{delay}}> \\ [\\rm{Gyr}]$'\n",
    "                elif whichQuantity=='fraction':\n",
    "                    mask_systems = param_x[mask_MRR][mask_ZZ] <= value_for_fraction\n",
    "                    median_at_ZZ[ind_Z] = np.sum(weights_[mask_MRR][mask_ZZ][mask_systems])/np.sum(weights_[mask_MRR][mask_ZZ])\n",
    "                    nameY = r'$\\rm{fraction }  t_{\\rm{delay}} < %s \\ [\\rm{Gyr}]$'%value_for_fraction\n",
    "                        \n",
    "\n",
    "        axe.scatter(np.log10(np.unique(metallicities)), median_at_ZZ, color=c_FC, marker=dictMarkerShape[BPSmodelName])\n",
    "        axe.plot(np.log10(np.unique(metallicities)),    median_at_ZZ, color=c_FC) #, ls=linestyles_mssfrind[ind_mssfr_zind])\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    # always close the dataset\n",
    "    fdata.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     ylabel = r'\\textbf{Rate}'\n",
    "        \n",
    "        \n",
    "    xlabel = r'\\textbf{Metallicity} \\ $Z$'\n",
    "    ylabel = nameY\n",
    "    \n",
    "    axe = layoutAxes(axe, nameX=xlabel, nameY=ylabel, setMinor=True)\n",
    "\n",
    "    \n",
    "#     axe.set_xlim(0.001,0.3)\n",
    "    if whichQuantity=='fraction':\n",
    "        axe.set_ylim(0., 1)\n",
    "#     else:\n",
    "#         axe.set_ylim(1, 1E4)\n",
    "    if whichQuantity=='median':\n",
    "        axe.set_yscale('log')\n",
    "    \n",
    "#     axe.set_xscale('log')\n",
    "    \n",
    "    if add_model_label==True:\n",
    "        bbox_props = dict(boxstyle=\"round\", fc=\"w\", ec=\"0.5\", alpha=0.95)\n",
    "        axe.annotate(r'\\textbf{model %s:}'%(BPSmodelName) +'\\n' + alphabetPhysicalNameDict[BPSmodelName], xy=(0.042, .95),\\\n",
    "                     xycoords='axes fraction', fontsize = fs, weight = 'bold', ha='left', va=\"top\",bbox=bbox_props,\\\n",
    "                    zorder=1E10)\n",
    "\n",
    "    return axe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524b2436",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot delay times with fraction \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "whichQuantity='median'\n",
    "\n",
    "# for ind_m, BPSmodelName in  enumerate([BPSnameslist[0]]):\n",
    "for ind_m, BPSmodelName in  enumerate(BPSnameslist[:]):\n",
    "#     color_m = colorDirDict[BPSmodelName]\n",
    "    print('at BPS model ', BPSmodelName)\n",
    "\n",
    "    for DCOtype in ['BBH']: #'BNS', 'BHNS', \n",
    "        print()\n",
    "        print('at DCOtype =', DCOtype)\n",
    "    #     for nrC, Channel in enumerate(adjustedChannelList): \n",
    "    #     for nrC, Channel in enumerate([adjustedChannelList[0]]): \n",
    "    #         print('now at Channel', Channel)\n",
    "\n",
    "        ncols, nrows= 1,1\n",
    "        f, ax= plt.subplots(ncols=ncols,nrows=nrows,figsize=(10,8), \n",
    "                      gridspec_kw={\"width_ratios\":1.5*np.ones(ncols), \"height_ratios\":1*np.ones(nrows)})\n",
    "\n",
    "\n",
    "\n",
    "        ax = plot_formation_channels_metallicity_xparam(axe=ax, DCOtype=DCOtype, BPSmodelName=BPSmodelName,\\\n",
    "                                                              pathData=pathData,\\\n",
    "                                                            mask_specific_mssfr=None,\\\n",
    "                                                         whichQuantity=whichQuantity, value_for_fraction=False, add_model_label=True) \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        ##  SAVE FIG  ###\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(wspace=0., hspace=0.18)  \n",
    "        plt.savefig('./formation_median/delay_time/delay_time_ratesMetallicity_' +  DCOtype + '_' + BPSmodelName + '_' + whichQuantity + '.png', transparent=False, dpi=300)\n",
    "        plt.savefig('./formation_median/delay_time/delay_time_ratesMetallicity_' +  DCOtype + '_' + BPSmodelName + '_' + whichQuantity + '.pdf', transparent=True)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85367edf",
   "metadata": {},
   "source": [
    "## all in one figure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec1c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "whichQuantity='median'\n",
    "ncols, nrows= 1,1\n",
    "f, ax= plt.subplots(ncols=ncols,nrows=nrows,figsize=(10,8), \n",
    "              gridspec_kw={\"width_ratios\":1.5*np.ones(ncols), \"height_ratios\":1*np.ones(nrows)})\n",
    "# for ind_m, BPSmodelName in  enumerate([BPSnameslist[0]]):\n",
    "for ind_m, BPSmodelName in  enumerate(BPSnameslist[:]):\n",
    "#     color_m = colorDirDict[BPSmodelName]\n",
    "    print('at BPS model ', BPSmodelName)\n",
    "\n",
    "    for DCOtype in ['BBH']: #'BNS', 'BHNS', \n",
    "        print()\n",
    "        print('at DCOtype =', DCOtype)\n",
    "    #     for nrC, Channel in enumerate(adjustedChannelList): \n",
    "    #     for nrC, Channel in enumerate([adjustedChannelList[0]]): \n",
    "    #         print('now at Channel', Channel)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ax = plot_formation_channels_metallicity_xparam(axe=ax, DCOtype=DCOtype, BPSmodelName=BPSmodelName,\\\n",
    "                                                              pathData=pathData,\\\n",
    "                                                            mask_specific_mssfr=None,\\\n",
    "                                                         whichQuantity=whichQuantity, value_for_fraction=False, add_model_label=False) \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "##  SAVE FIG  ###\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0., hspace=0.18)  \n",
    "plt.savefig('./formation_median/delay_time/delay_time_ratesMetallicity_' +  DCOtype + '_' + 'combi' + '_' + whichQuantity + '.png', transparent=False, dpi=300)\n",
    "plt.savefig('./formation_median/delay_time/delay_time_ratesMetallicity_' +  DCOtype + '_' + 'combi' + '_' + whichQuantity + '.pdf', transparent=True)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e07f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c227bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Change the above to include and go to zero if metallicity doesnt exist. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
